{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from  sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfull = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1      2    3      4      5     6       7    8      9    10  \\\n",
       "0    0.00632  18.0   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
       "1    0.02731   0.0   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
       "2    0.02729   0.0   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
       "3    0.03237   0.0   2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       "4    0.06905   0.0   2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
       "..       ...   ...    ...  ...    ...    ...   ...     ...  ...    ...   ...   \n",
       "501  0.06263   0.0  11.93  0.0  0.573  6.593  69.1  2.4786  1.0  273.0  21.0   \n",
       "502  0.04527   0.0  11.93  0.0  0.573  6.120  76.7  2.2875  1.0  273.0  21.0   \n",
       "503  0.06076   0.0  11.93  0.0  0.573  6.976  91.0  2.1675  1.0  273.0  21.0   \n",
       "504  0.10959   0.0  11.93  0.0  0.573  6.794  89.3  2.3889  1.0  273.0  21.0   \n",
       "505  0.04741   0.0  11.93  0.0  0.573  6.030  80.8  2.5050  1.0  273.0  21.0   \n",
       "\n",
       "         11    12  \n",
       "0    396.90  4.98  \n",
       "1    396.90  9.14  \n",
       "2    392.83  4.03  \n",
       "3    394.63  2.94  \n",
       "4    396.90  5.33  \n",
       "..      ...   ...  \n",
       "501  391.99  9.67  \n",
       "502  396.90  9.08  \n",
       "503  396.90  5.64  \n",
       "504  393.45  6.48  \n",
       "505  396.90  7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xfull.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 人为制造缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_p = 0.5\n",
    "total_num = Xfull.shape[0] * Xfull.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_missing_samples = int(np.floor(total_num * missing_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3289"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_missing_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_feature = rng.randint(0,Xfull.shape[0],n_missing_samples)\n",
    "missing_samples = rng.randint(0,Xfull.shape[1],n_missing_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_missing = X.copy()\n",
    "y_missing = y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_missing[missing_feature,missing_samples] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_missing = pd.DataFrame(X_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>242.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>273.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    1      2    3      4      5     6       7    8      9    10  \\\n",
       "0        NaN  NaN   2.31  0.0    NaN  6.575  65.2  4.0900  1.0    NaN   NaN   \n",
       "1    0.02731  0.0    NaN  0.0  0.469  6.421   NaN  4.9671  2.0  242.0  17.8   \n",
       "2    0.02729  NaN   7.07  0.0    NaN  7.185   NaN  4.9671  NaN  242.0   NaN   \n",
       "3    0.03237  0.0    NaN  NaN  0.458    NaN   NaN     NaN  NaN  222.0  18.7   \n",
       "4        NaN  0.0   2.18  0.0  0.458    NaN  54.2     NaN  3.0    NaN  18.7   \n",
       "..       ...  ...    ...  ...    ...    ...   ...     ...  ...    ...   ...   \n",
       "501  0.06263  NaN  11.93  NaN  0.573  6.593  69.1  2.4786  1.0  273.0  21.0   \n",
       "502  0.04527  0.0  11.93  0.0  0.573  6.120   NaN  2.2875  NaN  273.0  21.0   \n",
       "503  0.06076  0.0  11.93  NaN    NaN    NaN   NaN  2.1675  1.0  273.0  21.0   \n",
       "504      NaN  NaN    NaN  NaN    NaN  6.794   NaN     NaN  1.0    NaN  21.0   \n",
       "505  0.04741  NaN    NaN  0.0  0.573    NaN  80.8  2.5050  NaN  273.0   NaN   \n",
       "\n",
       "         11    12  \n",
       "0       NaN   NaN  \n",
       "1       NaN  9.14  \n",
       "2    392.83  4.03  \n",
       "3    394.63   NaN  \n",
       "4    396.90   NaN  \n",
       "..      ...   ...  \n",
       "501  391.99  9.67  \n",
       "502  396.90  9.08  \n",
       "503  396.90  5.64  \n",
       "504     NaN  6.48  \n",
       "505  396.90  7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用均值填充缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_missing_mean = SimpleImputer(missing_values=np.nan,strategy='mean').fit_transform(X_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用0填充缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_missing_0 = SimpleImputer(missing_values=np.nan,strategy=\"constant\",fill_value=0).fit_transform(X_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用随机森林回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n任何回归都是从特征矩阵中学习，然后求解连续型标签y的过程，之所以能够实现这个过程，\\n是因为回归算法认为，特征 矩阵和标签之前存在着某种联系。实际上，标签和特征是可以相互转换的，\\n比如说，在一个“用地区，环境，附近学校数 量”预测“房价”的问题中，\\n我们既可以用“地区”，“环境”，“附近学校数量”的数据来预测“房价”，\\n也可以反过来， 用“环境”，“附近学校数量”和“房价”来预测“地区”。而回归填补缺失值，正是利用了这种思想。\\n\\n对于一个有n个特征的数据来说，其中特征T有缺失值，我们就把特征T当作标签，其他的n-1个特征和原本的标签组成新 的特征矩阵。\\n那对于T来说，它没有缺失的部分，就是我们的Y_trian，这部分数据既有标签也有特征，而它缺失的部分，只有特征没有标签，就是我们需要预测的部分。\\n\\n\\n特征T不缺失的值对应的其他n-1个特征 + 本来的标签:X_train 特征T不缺失的值:Y_train\\n\\n特征T缺失的值对应的其他n-1个特征 + 本来的标签:X_test 特征T缺失的值:未知，我们需要预测的Y_test\\n\\n这种做法，对于某一个特征大量缺失，其他特征却很完整的情况，非常适用。\\n那如果数据中除了特征T之外，其他特征也有缺失值怎么办? \\n答案是遍历所有的特征，从缺失最少的开始进行填补(因为填补缺失最少的特征所需要的准确信息最少)。 \\n填补一个特征时，先将其他特征的缺失值用0代替，每完成一次回归预测，就将预测值放到原本的特征矩阵中，再继续填 补下一个特征。\\n每一次填补完毕，有缺失值的特征会减少一个，所以每次循环后，需要用0来填补的特征就越来越少。\\n当进行到最后一个特征时(这个特征应该是所有特征中缺失值最多的)，\\n已经没有任何的其他特征需要用0来进行填补了， 而我们已经使用回归为其他特征填补了大量有效信息，可以用来填补缺失最多的特征。\\n遍历所有的特征后，数据就完整，不再有缺失值了。\\n\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "任何回归都是从特征矩阵中学习，然后求解连续型标签y的过程，之所以能够实现这个过程，\n",
    "是因为回归算法认为，特征 矩阵和标签之前存在着某种联系。实际上，标签和特征是可以相互转换的，\n",
    "比如说，在一个“用地区，环境，附近学校数 量”预测“房价”的问题中，\n",
    "我们既可以用“地区”，“环境”，“附近学校数量”的数据来预测“房价”，\n",
    "也可以反过来， 用“环境”，“附近学校数量”和“房价”来预测“地区”。而回归填补缺失值，正是利用了这种思想。\n",
    "\n",
    "对于一个有n个特征的数据来说，其中特征T有缺失值，我们就把特征T当作标签，其他的n-1个特征和原本的标签组成新 的特征矩阵。\n",
    "那对于T来说，它没有缺失的部分，就是我们的Y_trian，这部分数据既有标签也有特征，而它缺失的部分，只有特征没有标签，就是我们需要预测的部分。\n",
    "\n",
    "\n",
    "特征T不缺失的值对应的其他n-1个特征 + 本来的标签:X_train 特征T不缺失的值:Y_train\n",
    "\n",
    "特征T缺失的值对应的其他n-1个特征 + 本来的标签:X_test 特征T缺失的值:未知，我们需要预测的Y_test\n",
    "\n",
    "这种做法，对于某一个特征大量缺失，其他特征却很完整的情况，非常适用。\n",
    "那如果数据中除了特征T之外，其他特征也有缺失值怎么办? \n",
    "答案是遍历所有的特征，从缺失最少的开始进行填补(因为填补缺失最少的特征所需要的准确信息最少)。 \n",
    "填补一个特征时，先将其他特征的缺失值用0代替，每完成一次回归预测，就将预测值放到原本的特征矩阵中，再继续填 补下一个特征。\n",
    "每一次填补完毕，有缺失值的特征会减少一个，所以每次循环后，需要用0来填补的特征就越来越少。\n",
    "当进行到最后一个特征时(这个特征应该是所有特征中缺失值最多的)，\n",
    "已经没有任何的其他特征需要用0来进行填补了， 而我们已经使用回归为其他特征填补了大量有效信息，可以用来填补缺失最多的特征。\n",
    "遍历所有的特征后，数据就完整，不再有缺失值了。\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_missing_reg = X_missing.copy()\n",
    "#找缺省值排序的索引\n",
    "sortindex = np.argsort(X_missing_reg.isnull().sum(axis=0)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  2,  1,  3,  8,  0,  9,  4, 12,  5, 10, 11,  6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "for i in sortindex:\n",
    "    df = X_missing_reg.copy()\n",
    "    # 需要填补的那一列\n",
    "    fillc = df.iloc[:,i]\n",
    "    # 把剩下的 和 原本的label 合起来 组成\n",
    "    \n",
    "    df = pd.concat([df.iloc[:,df.columns != df.columns[i]],pd.DataFrame(y)],axis=1)\n",
    "    \n",
    "    #对新的特征矩阵 填补0\n",
    "    df_0 =SimpleImputer(missing_values=np.nan,strategy='constant',fill_value=0).fit_transform(df)\n",
    "    \n",
    "    Ytrain = fillc[fillc.notnull()] \n",
    "    Xtrain = df_0[Ytrain.index,:] \n",
    "    \n",
    "    Ytest = fillc[fillc.isnull()]\n",
    "    Xtest = df_0[Ytest.index,:]\n",
    "    \n",
    "    \n",
    "    rfc = RandomForestRegressor(n_estimators=100) \n",
    "    rfc = rfc.fit(Xtrain, Ytrain)\n",
    "    Ypredict = rfc.predict(Xtest)\n",
    "    X_missing_reg.iloc[X_missing_reg.iloc[:,i].isnull().values,i] = Ypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.133734</td>\n",
       "      <td>7.220</td>\n",
       "      <td>2.3100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.462966</td>\n",
       "      <td>6.57500</td>\n",
       "      <td>65.200</td>\n",
       "      <td>4.090000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>238.14</td>\n",
       "      <td>18.657</td>\n",
       "      <td>391.4549</td>\n",
       "      <td>7.9601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027310</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.3493</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.469000</td>\n",
       "      <td>6.42100</td>\n",
       "      <td>44.403</td>\n",
       "      <td>4.967100</td>\n",
       "      <td>2.00</td>\n",
       "      <td>242.00</td>\n",
       "      <td>17.800</td>\n",
       "      <td>390.9184</td>\n",
       "      <td>9.1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027290</td>\n",
       "      <td>28.275</td>\n",
       "      <td>7.0700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.437655</td>\n",
       "      <td>7.18500</td>\n",
       "      <td>27.893</td>\n",
       "      <td>4.967100</td>\n",
       "      <td>4.59</td>\n",
       "      <td>242.00</td>\n",
       "      <td>16.119</td>\n",
       "      <td>392.8300</td>\n",
       "      <td>4.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.032370</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.1915</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>7.11421</td>\n",
       "      <td>48.448</td>\n",
       "      <td>4.398992</td>\n",
       "      <td>3.96</td>\n",
       "      <td>222.00</td>\n",
       "      <td>18.700</td>\n",
       "      <td>394.6300</td>\n",
       "      <td>4.9815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.050712</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>7.07059</td>\n",
       "      <td>54.200</td>\n",
       "      <td>4.754735</td>\n",
       "      <td>3.00</td>\n",
       "      <td>215.61</td>\n",
       "      <td>18.700</td>\n",
       "      <td>396.9000</td>\n",
       "      <td>5.8896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.062630</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.9300</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>6.59300</td>\n",
       "      <td>69.100</td>\n",
       "      <td>2.478600</td>\n",
       "      <td>1.00</td>\n",
       "      <td>273.00</td>\n",
       "      <td>21.000</td>\n",
       "      <td>391.9900</td>\n",
       "      <td>9.6700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.045270</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.9300</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>6.12000</td>\n",
       "      <td>79.919</td>\n",
       "      <td>2.287500</td>\n",
       "      <td>4.18</td>\n",
       "      <td>273.00</td>\n",
       "      <td>21.000</td>\n",
       "      <td>396.9000</td>\n",
       "      <td>9.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.060760</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.9300</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.576330</td>\n",
       "      <td>6.67689</td>\n",
       "      <td>77.569</td>\n",
       "      <td>2.167500</td>\n",
       "      <td>1.00</td>\n",
       "      <td>273.00</td>\n",
       "      <td>21.000</td>\n",
       "      <td>396.9000</td>\n",
       "      <td>5.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.060748</td>\n",
       "      <td>14.970</td>\n",
       "      <td>4.3977</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.450877</td>\n",
       "      <td>6.79400</td>\n",
       "      <td>38.471</td>\n",
       "      <td>5.840833</td>\n",
       "      <td>1.00</td>\n",
       "      <td>283.08</td>\n",
       "      <td>21.000</td>\n",
       "      <td>388.6409</td>\n",
       "      <td>6.4800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.047410</td>\n",
       "      <td>0.000</td>\n",
       "      <td>15.4886</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>6.21932</td>\n",
       "      <td>80.800</td>\n",
       "      <td>2.505000</td>\n",
       "      <td>15.43</td>\n",
       "      <td>273.00</td>\n",
       "      <td>19.348</td>\n",
       "      <td>396.9000</td>\n",
       "      <td>7.8800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1        2     3         4        5       6         7  \\\n",
       "0    0.133734   7.220   2.3100  0.00  0.462966  6.57500  65.200  4.090000   \n",
       "1    0.027310   0.000   6.3493  0.00  0.469000  6.42100  44.403  4.967100   \n",
       "2    0.027290  28.275   7.0700  0.00  0.437655  7.18500  27.893  4.967100   \n",
       "3    0.032370   0.000   4.1915  0.01  0.458000  7.11421  48.448  4.398992   \n",
       "4    0.050712   0.000   2.1800  0.00  0.458000  7.07059  54.200  4.754735   \n",
       "..        ...     ...      ...   ...       ...      ...     ...       ...   \n",
       "501  0.062630   0.000  11.9300  0.15  0.573000  6.59300  69.100  2.478600   \n",
       "502  0.045270   0.000  11.9300  0.00  0.573000  6.12000  79.919  2.287500   \n",
       "503  0.060760   0.000  11.9300  0.02  0.576330  6.67689  77.569  2.167500   \n",
       "504  0.060748  14.970   4.3977  0.12  0.450877  6.79400  38.471  5.840833   \n",
       "505  0.047410   0.000  15.4886  0.00  0.573000  6.21932  80.800  2.505000   \n",
       "\n",
       "         8       9      10        11      12  \n",
       "0     1.00  238.14  18.657  391.4549  7.9601  \n",
       "1     2.00  242.00  17.800  390.9184  9.1400  \n",
       "2     4.59  242.00  16.119  392.8300  4.0300  \n",
       "3     3.96  222.00  18.700  394.6300  4.9815  \n",
       "4     3.00  215.61  18.700  396.9000  5.8896  \n",
       "..     ...     ...     ...       ...     ...  \n",
       "501   1.00  273.00  21.000  391.9900  9.6700  \n",
       "502   4.18  273.00  21.000  396.9000  9.0800  \n",
       "503   1.00  273.00  21.000  396.9000  5.6400  \n",
       "504   1.00  283.08  21.000  388.6409  6.4800  \n",
       "505  15.43  273.00  19.348  396.9000  7.8800  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_missing_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "X = [Xfull,X_missing_mean,X_missing_0,X_missing_reg]\n",
    "mse = []\n",
    "std = []\n",
    "for x in X:\n",
    "    estimator = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "    scores = cross_val_score(estimator,x,y,scoring='neg_mean_squared_error', cv=5).mean()\n",
    "    mse.append(scores * -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_labels = ['Full data',\n",
    "            'Zero Imputation',\n",
    "            'Mean Imputation',\n",
    "            'Regressor Imputation']\n",
    "colors = ['r', 'g', 'b', 'orange']\n",
    "plt.figure(figsize=(12, 6)) \n",
    "ax = plt.subplot(111)\n",
    "for i in np.arange(len(mse)):\n",
    "    ax.barh(i, mse[i],color=colors[i], alpha=0.6, align='center') \n",
    "ax.set_title('Imputation Techniques with Boston Data')\n",
    "ax.set_xlim(left=np.min(mse) * 0.9,\n",
    "right=np.max(mse) * 1.1)\n",
    "ax.set_yticks(np.arange(len(mse)))\n",
    "ax.set_xlabel('MSE') \n",
    "ax.set_yticklabels(x_labels) \n",
    "plt.show()\n",
    "rfc = RandomForestRegressor(n_estimators=100) \n",
    "rfc = rfc.fit(Xtrain, Ytrain)\n",
    "Ypredict = rfc.predict(Xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*X_missing_reg.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "0  1  4  7\n",
      "1  2  5  8\n",
      "2  3  6  9\n"
     ]
    }
   ],
   "source": [
    "df1=pd.DataFrame({'A':[1,2,3],'B':[4,5,6],'C':[7,8,9]})\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns != 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
